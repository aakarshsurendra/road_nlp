{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e92be1-ba67-4e1c-8490-76e74eb80821",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# __ init __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11ce47e-64ea-49a7-b5ea-7e7249d9a6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "064cc8ed-1a90-477c-b7bf-21c58bb14656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_data_from_pickle(filename):\n",
    "    \"\"\"\n",
    "    Load data from a pickle file.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): The filename of the pickle file.\n",
    "        \n",
    "    Returns:\n",
    "        The loaded data.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Data loaded from {filename} successfully.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0869372a-0a38-489d-a29c-3c0c23c89614",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from train_data_400.pickle successfully.\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data_from_pickle(\"train_data_400.pickle\") #.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65882bdb-6901-45a3-8f1f-9ee1c65a1087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from test_data.pickle successfully.\n"
     ]
    }
   ],
   "source": [
    "test_data = load_data_from_pickle(\"test_data.pickle\") #.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73fa9e-f535-46d1-8797-b54094fe6bf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model Build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf6bb4-8b75-488a-ba6e-bc31a2208b7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d324d4f-08d9-4cfe-a95d-23622310bbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# This code initializes the configuration for spaCy using the 'base_config.cfg' file and fills it with specific train and test file paths,\n",
    "# creating a customized configuration file named 'config.cfg'. This step is crucial for setting up the spaCy pipeline with the necessary \n",
    "# parameters and data paths for training and testing models.\n",
    "\n",
    "!python -m spacy init fill-config roberta_base_config.cfg config.cfg #open and include train and test file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4c793-8572-47dc-af3e-5114cadda21b",
   "metadata": {},
   "source": [
    "If your training data size is 775, and your batch size is 128, you'll have approximately 6 batches per epoch (775 / 128 ≈ 6.05). To ensure you cover the entire dataset for 4 epochs, you'd use the following calculation:\n",
    "\n",
    "max_steps = batches_per_epoch × max_epochs\n",
    "\n",
    "max_steps = 6 × 4 = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a540263-a1e4-4d3e-a712-012e37d20787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================ Data file validation ============================\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[38;5;2m✔ Pipeline can be initialized with data\u001b[0m\n",
      "\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
      "\u001b[1m\n",
      "=============================== Training stats ===============================\u001b[0m\n",
      "Language: en\n",
      "Training pipeline: transformer, ner\n",
      "400 training docs\n",
      "186 evaluation docs\n",
      "\u001b[38;5;2m✔ No overlap between training and evaluation data\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples to train a new pipeline (400)\u001b[0m\n",
      "\u001b[1m\n",
      "============================== Vocab & Vectors ==============================\u001b[0m\n",
      "\u001b[38;5;4mℹ 12749 total word(s) in the data (1795 unique)\u001b[0m\n",
      "\u001b[38;5;4mℹ No word vectors present in the package\u001b[0m\n",
      "\u001b[1m\n",
      "========================== Named Entity Recognition ==========================\u001b[0m\n",
      "\u001b[38;5;4mℹ 7 label(s)\u001b[0m\n",
      "0 missing value(s) (tokens with '-' label)\n",
      "\u001b[38;5;2m✔ Good amount of examples for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities consisting of or starting/ending with whitespace\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities crossing sentence boundaries\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Summary ==================================\u001b[0m\n",
      "\u001b[38;5;2m✔ 7 checks passed\u001b[0m\n",
      "\u001b[38;5;3m⚠ 1 warning\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This code utilizes spaCy's debugging tool to examine the data specified in the 'config.cfg' configuration file.\n",
    "# By running the command 'python -m spacy debug data config.cfg', it enables detailed inspection of the data sources,\n",
    "# annotations, and other \n",
    "\n",
    "!python -m spacy debug data config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666b5fab-605d-4bdf-aadd-b245e6143585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output/502\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0        1199.23    807.59    0.12    0.08    0.30    0.00\n",
      " 26     200       93155.34  65845.22   82.47   79.06   86.19    0.82\n",
      " 53     400        4589.49   3679.01   81.04   78.21   84.08    0.81\n",
      " 80     600         771.21    894.20   82.51   85.14   80.03    0.83\n",
      "106     800         526.38    602.55   81.79   82.67   80.93    0.82\n",
      "133    1000         404.39    438.06   82.95   82.27   83.63    0.83\n",
      "160    1200         302.71    336.92   80.73   81.92   79.58    0.81\n",
      "187    1400         240.11    255.67   82.37   81.29   83.48    0.82\n",
      "214    1600         244.57    250.17   81.54   80.53   82.58    0.82\n",
      "240    1800         187.36    198.10   80.19   83.80   76.88    0.80\n",
      "266    2000         156.01    159.07   82.61   83.56   81.68    0.83\n",
      "293    2200         165.80    165.50   82.57   80.28   84.98    0.83\n",
      "320    2400         162.39    163.93   82.24   81.75   82.73    0.82\n",
      "346    2600         146.22    148.91   81.27   78.38   84.38    0.81\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/502/model-last\n"
     ]
    }
   ],
   "source": [
    "# config.cfg ## replace with a unique config file id\n",
    "!python -m spacy train config.cfg --output ./output/502/ --paths.train ./train_400.spacy --paths.dev ./test.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e7339-be70-43f3-80a1-c32b66ce6be6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Predictions (Test Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058031b-eae7-4098-bd13-2aa949982229",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08930d54-d5ca-4481-ab8e-038b42268da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '502'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8f664d-e8a7-47a3-95de-f6415b637a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "test_nlp = spacy.load(f'./output/{502}/model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0642e146-df2a-4a64-b3ad-61261f6f29f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AGE', 'FATALITIES', 'GENDER', 'INJURED', 'REASON', 'TIME', 'VEHICLE TYPE')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nlp.get_pipe('ner').labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5b8433-c132-49d4-8c4e-22c610e18139",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b01deca3-2c02-4c85-b152-f29146c83964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entity_names = [\"AGE\", \"VEHICLE TYPE\", \"REASON\", \"FATALITIES\", \"INJURED\", \"GENDER\", \"TIME\"]\n",
    "\n",
    "# Define colors for each entity\n",
    "colors = {entity: \"#{}\".format(hash(entity) & 0x00FFFFF) for entity in entity_names}\n",
    "\n",
    "\n",
    "light_colors = {\n",
    "    \"AGE\": \"#FFDDC1\",          # Light orange\n",
    "    \"VEHICLE TYPE\": \"#D0E1F9\", # Light blue\n",
    "    \"REASON\": \"#FFB6C1\",       # Light peach\n",
    "    \"FATALITIES\": \"#C8E6C9\",   # Light green\n",
    "    \"INJURED\": \"#FFE0B2\",      # Light amber\n",
    "    \"GENDER\": \"#F0F4C3\",       # Light yellow\n",
    "    \"TIME\": \"#E1BEE7\"          # Light purple\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88289b34-31ce-4bc2-adf8-f134ee2e02be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = 'A man in his 40s was injured and his mother-in-law seriously injured when their tractor dashed against a tree in this district, police said on Thursday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14d5850f-1bfc-4597-9fb2-d9ce0a83e1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = test_nlp(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77a33d1b-8279-4913-9a3e-98a831bbc464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A \n",
       "<mark class=\"entity\" style=\"background: #F0F4C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    man\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENDER</span>\n",
       "</mark>\n",
       " in his \n",
       "<mark class=\"entity\" style=\"background: #FFDDC1; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    40s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">AGE</span>\n",
       "</mark>\n",
       " was injured and his \n",
       "<mark class=\"entity\" style=\"background: #F0F4C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mother-in-law\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENDER</span>\n",
       "</mark>\n",
       " seriously injured when their \n",
       "<mark class=\"entity\" style=\"background: #D0E1F9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tractor\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VEHICLE TYPE</span>\n",
       "</mark>\n",
       " dashed against a \n",
       "<mark class=\"entity\" style=\"background: #FFB6C1; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tree\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">REASON</span>\n",
       "</mark>\n",
       " in this district, police said on Thursday</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True, options={\"colors\": light_colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67683ff8-5b28-4ab0-b71e-265155282550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = 'A 40-year-old drunk man was killed and his wife seriously injured when their car dashed against a tree in this district, police said on Thursday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aae4db78-d54f-417f-95da-fd5754e98f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = test_nlp(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cacda282-5442-42ae-8b22-2267264bbb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A \n",
       "<mark class=\"entity\" style=\"background: #FFDDC1; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    40-year-old\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">AGE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FFB6C1; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    drunk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">REASON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #F0F4C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    man\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENDER</span>\n",
       "</mark>\n",
       " was killed and his \n",
       "<mark class=\"entity\" style=\"background: #F0F4C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    wife\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GENDER</span>\n",
       "</mark>\n",
       " seriously injured when their \n",
       "<mark class=\"entity\" style=\"background: #D0E1F9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    car\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VEHICLE TYPE</span>\n",
       "</mark>\n",
       " dashed against a \n",
       "<mark class=\"entity\" style=\"background: #FFB6C1; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tree\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">REASON</span>\n",
       "</mark>\n",
       " in this district, police said on Thursday</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True , options={\"colors\": light_colors})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c796a-a074-482e-b6f9-7d4e3f49ca67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performance Metrics Evaluvation (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3ada31-3e27-4414-a73e-880744af3cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = '502' # Add the model name here\n",
    "description = ''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37033b82-d01a-492b-83a4-b5d1b0e231bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize lists to store row-wise scores\n",
    "data_rows = []\n",
    "\n",
    "# Iterate through test data\n",
    "for data in test_data:\n",
    "    true_positives, false_positives, false_negatives = 0, 0, 0  # Reset counts for each data row\n",
    "    if data is None:\n",
    "        print(\"Skipping None value in test data.\")\n",
    "        continue\n",
    "\n",
    "    text, annotations = data\n",
    "    doc = test_nlp(text)\n",
    "    predicted_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    true_entities = [(text[start:end], label) for start, end, label in annotations.get('entities', [])]\n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives for each row\n",
    "    for entity in predicted_entities:\n",
    "        if entity in true_entities:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "\n",
    "    for entity in true_entities:\n",
    "        if entity not in predicted_entities:\n",
    "            false_negatives += 1\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for the current row\n",
    "    row_accuracy = true_positives / (true_positives + false_positives + false_negatives) if (true_positives + false_positives + false_negatives) > 0 else 0\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Append row-wise scores to the data_rows list\n",
    "    data_rows.append({\n",
    "        'Text': text,\n",
    "        'Predicted Entities': predicted_entities,\n",
    "        'Annotated Entities': true_entities,\n",
    "        'Accuracy': row_accuracy,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the data_rows list\n",
    "df_predicted = pd.DataFrame(data_rows)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_predicted.head()\n",
    "\n",
    "df_predicted.to_csv(f'{model_name}_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a00daa2-2f19-4676-971d-3d0347700e09",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Weighted avg and convert to df above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a8c5fe8-7cda-4273-875d-4031424da043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize variables to store true positives, false positives, and false negatives for each entity type\n",
    "tp = defaultdict(int)\n",
    "fp = defaultdict(int)\n",
    "fn = defaultdict(int)\n",
    "te = defaultdict(int)\n",
    "\n",
    "# Iterate over the test data\n",
    "for data in test_data:\n",
    "    if data is None:\n",
    "        continue\n",
    "    \n",
    "    text, annotations = data\n",
    "    doc = test_nlp(text)\n",
    "    predicted_entities = {(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents}\n",
    "    true_entities = {(start, end, label) for start, end, label in annotations.get('entities', [])}\n",
    "    \n",
    "    # Compute true positives, false positives, false negatives, and true entity count\n",
    "    for ent in predicted_entities:\n",
    "        if ent in true_entities:\n",
    "            tp[ent[2]] += 1\n",
    "        else:\n",
    "            fp[ent[2]] += 1\n",
    "    for ent in true_entities:\n",
    "        if ent not in predicted_entities:\n",
    "            fn[ent[2]] += 1\n",
    "        te[ent[2]] += 1  # Increment true entity count for every true entity\n",
    "\n",
    "# Compute precision, recall, and F1-score for each entity type\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1 = {}\n",
    "for label in test_nlp.get_pipe('ner').labels:\n",
    "    precision[label] = tp[label] / (tp[label] + fp[label]) if tp[label] + fp[label] > 0 else 0\n",
    "    recall[label] = tp[label] / (tp[label] + fn[label]) if tp[label] + fn[label] > 0 else 0\n",
    "    f1[label] = 2 * (precision[label] * recall[label]) / (precision[label] + recall[label]) if precision[label] + recall[label] > 0 else 0\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "data_for_df = []\n",
    "for label in test_nlp.get_pipe('ner').labels:\n",
    "    data_for_df.append([label, te[label], round(precision[label], 3), round(recall[label], 3), round(f1[label], 3)])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data_for_df, columns=['Entity Type', 'Count', 'Precision', 'Recall', 'F1-score'])\n",
    "\n",
    "# Calculate weighted averages\n",
    "weighted_precision = (df['Precision'] * df['Count']).sum() / df['Count'].sum()\n",
    "weighted_recall = (df['Recall'] * df['Count']).sum() / df['Count'].sum()\n",
    "weighted_f1 = (df['F1-score'] * df['Count']).sum() / df['Count'].sum()\n",
    "\n",
    "# Add weighted averages to the DataFrame\n",
    "weighted_averages = pd.DataFrame([['Weighted Average', '', round(weighted_precision, 3), round(weighted_recall, 3), round(weighted_f1, 3)]],\n",
    "                                 columns=['Entity Type', 'Count', 'Precision', 'Recall', 'F1-score'])\n",
    "df = pd.concat([df, weighted_averages], ignore_index=True)\n",
    "\n",
    "df['Model'] = model_name\n",
    "df.head()\n",
    "\n",
    "\n",
    "df.to_csv(f'{model_name}_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7359c40-c050-45fb-9dd1-d4bb398c7740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.6 s, sys: 13.7 s, total: 55.3 s\n",
      "Wall time: 7.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture captured_output\n",
    "\n",
    "# Initialize lists to store row-wise scores\n",
    "precision_list, recall_list, f1_list = [], [], []\n",
    "true_positives, false_positives, false_negatives = 0, 0, 0\n",
    "\n",
    "# Iterate through test data\n",
    "for data in test_data:\n",
    "    true_positives, false_positives, false_negatives = 0, 0, 0  # Reset counts for each data row\n",
    "    if data is None:\n",
    "        print(\"Skipping None value in test data.\")\n",
    "        continue\n",
    "\n",
    "    text, annotations = data\n",
    "    doc = test_nlp(text)\n",
    "    predicted_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    true_entities = [(text[start:end], label) for start, end, label in annotations.get('entities', [])]\n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives for each row\n",
    "    for entity in predicted_entities:\n",
    "        if entity in true_entities:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "\n",
    "    for entity in true_entities:\n",
    "        if entity not in predicted_entities:\n",
    "            false_negatives += 1\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for the current row\n",
    "    row_accuracy = true_positives / (true_positives + false_positives + false_negatives) if (true_positives + false_positives + false_negatives) > 0 else 0\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Append row-wise scores to lists\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    # Print the results for each row\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Predicted entities:\", predicted_entities)\n",
    "    print(\"Annotated entities:\", true_entities)\n",
    "    print(\"Accuracy:\", row_accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print(\"---------------\")\n",
    "\n",
    "# Calculate accuracy, average precision, recall, and F1-score\n",
    "accuracy = true_positives / (true_positives + false_positives + false_negatives)\n",
    "avg_precision = sum(precision_list) / len(precision_list)\n",
    "avg_recall = sum(recall_list) / len(recall_list)\n",
    "avg_f1 = sum(f1_list) / len(f1_list)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-score:\", avg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51b93562-7c2e-4ced-b973-d2c125ac44bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This is used to log\n",
    "with open(f'macro_metrics_{model_name}.txt', 'w') as f:\n",
    "    f.write(captured_output.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a567d-4ba7-407e-97f9-5b1573b63b46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Backkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b02a7da9-cbf6-4dc7-ad32-b5faabf32851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "test_nlp = spacy.load('./output/spacy/model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92c4eed4-e7d7-4988-9a9c-98a3d99c51c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AGE', 'FATALITIES', 'GENDER', 'INJURED', 'REASON', 'TIME', 'VEHICLE TYPE')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nlp.get_pipe('ner').labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fff1e983-6031-44b8-8fb3-2ed934b75ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'raw_firstline.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the live data that needs to be classified\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_livedata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_firstline.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'raw_firstline.csv'"
     ]
    }
   ],
   "source": [
    "# Read the live data that needs to be classified\n",
    "df_livedata = pd.read_csv('raw_firstline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e5af4-e686-49cb-9190-db4d1d1fe61e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_article_id(url):\n",
    "    match = re.search(r'\\/(\\d+)\\.cms', url)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec72378-46d8-450d-a31f-6e8027db7ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_livedata['id'] = df_livedata['Link'].apply(extract_article_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc107020-7111-4d56-b665-00f3e6791a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File path where the annotated IDs are stored\n",
    "file_path = \"id_list_annotated.txt\"\n",
    "\n",
    "# Reading the contents of the text file into a list\n",
    "with open(file_path, 'r') as file:\n",
    "    id_list_read = file.readlines()\n",
    "\n",
    "# Removing newline characters from the elements of the list\n",
    "id_list_read = [item.strip() for item in id_list_read]\n",
    "\n",
    "# Converting the IDs from strings to integers\n",
    "id_list_read = [int(x) for x in id_list_read]\n",
    "\n",
    "# Creating a DataFrame from the list of IDs\n",
    "id_df = pd.DataFrame(id_list_read, columns=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f8e6f-d9c7-4988-992a-38012b5974d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Filter out the ids that have been used for training\n",
    "df_livedata = df_livedata[~df_livedata['id'].isin(id_list_read)]\n",
    "\n",
    "df_livedata = df_livedata[['id','content','First_Line']]  # Only filter out the id and the first line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
