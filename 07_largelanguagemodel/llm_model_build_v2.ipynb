{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a365d649-a6ef-425b-ac1a-4a6d729b1e2c",
   "metadata": {},
   "source": [
    "Readme:\n",
    "\n",
    "- Make sure do the following before running any code in this notebook\n",
    "    - Get your API key from ::https://ai.google.dev/?gad_source=1&gclid=CjwKCAjwz42xBhB9EiwA48pT78pVH2iyB1l-2HEWm2DNbYh4fqtwlqPsDFycvBplXbsVEEdmBmPplxoCvuYQAvD_BwE\n",
    "    - save your api key to 'gemini_api.txt'.\n",
    "    - run __init__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d903b3-192e-4a98-a7d9-4a2541deb8c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2665237-f4b8-4499-8e45-8804cbed10ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from word2number import w2n\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d414bc-7050-4079-8d20-4ffe549a71f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412c5ad5-8c0f-431e-9d0d-487d1b1192ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup_json(filename):\n",
    "    \"\"\"\n",
    "    Read a JSON file, filter out entries with value 'error:llm',\n",
    "    and update the file with the cleaned data.\n",
    "\n",
    "    Args:\n",
    "    - filename (str): The name of the JSON file to clean up.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "    else:\n",
    "        data = {}\n",
    "\n",
    "    # Filter out entries with 'error:llm'\n",
    "    cleaned_data = {key: value for key, value in data.items() if value != 'error:llm'}\n",
    "\n",
    "    # Write cleaned data back to the JSON file\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(cleaned_data, file)\n",
    "        \n",
    "        \n",
    "# example\n",
    "# cleanup_json('extraction_progress.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6ceba4-8895-4c51-9024-fffc67fe5e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to read API key from file\n",
    "def read_api_key(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        api_key = file.readline().strip()  # Read the first line and remove any leading/trailing whitespace\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa3a75-cb27-4cbd-ab88-8d38880f6e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "838fa564-c6db-4d2d-a7c1-a86809cbef48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data to be predicted\n",
    "df_livedata=pd.read_csv(\"filtered_news.csv\")\n",
    "df_livedata.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7801675-2d8f-475b-a9aa-c2fac50f18a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_livedata = df_livedata\n",
    "df_livedata = df_livedata[['id','content']]\n",
    "df_livedata['llm_completion_dict']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e576232-9f4f-4616-8fab-d6a19cf55e97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6750, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_livedata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf7e314-eeda-4c7e-a82d-f4903f5ef964",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Google Gemini pro api prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "280e259e-f969-4370-af20-9447e2473e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"fatalities\": 2,\"injured\":2,\"reason\":'negligence',\"victim_gender\":[\"Female\"],\"vehicles\":[\"car\",\"tractor\"],\"child_involved\":1,\"names_ages\":[(\"Swaroopa\",36),(\"Sri Lekha\",13),(\"Mallesham\",0),(\"Lavanya\",0)]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "At the command line, only need to run once to install the package via pip:\n",
    "\n",
    "$ pip install google-generativeai\n",
    "\"\"\"\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "api_key = read_api_key('gemini_api.txt')\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Set up the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0.15,\n",
    "  \"top_p\": 0.1,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 2048,\n",
    "  \"stop_sequences\": [\n",
    "    \"/\",\n",
    "  ],\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
    "                              generation_config=generation_config,\n",
    "                              safety_settings=safety_settings)\n",
    "\n",
    "convo = model.start_chat(history=[\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": [\"Learn these:\\n\\nInput:\\n'New Delhi: A two-and-a-half-year-old boy was crushed to death under a car while walking near a road in northwest Delhiâ€™s Mukherjee Nagar on Wednesday. The suspect, identified as Mehak Bansal (38), a businessman, has been arrested, police said. The incident which was captured by a CCTV camera, showed a red car colliding with the toddler as he was seen running to the other side. The accused, who was behind the wheel, inadvertently ran over the child, resulting in fatal injuries. Parents and bystanders rushed to the child\\\\'s aid, transporting him to hospital for urgent medical attention. \\\"Upon receiving the information, a team rushed to the hospital, where it was discovered that the child had succumbed to his injuries. A case has been registered under Section 279 for rash driving and Section 304(a) for death caused by negligence,\\\" said Jitender Meena, DCP (Northwest). Explore Your Financial Landscape with Personalized Credit Insights.'\\n\\noutput:{\\\"fatalities\\\": 1,\\\"injured\\\":0,\\\"reason\\\":'negligence',\\\"victim_gender\\\":[\\\"Male\\\"],\\\"vehicles\\\":[\\\"car\\\"],\\\"child_involved\\\":1,\\\"names_ages\\\":[(\\\"Mehak Bansal\\\",38),(\\\"unknown_name\\\",2.5)]}/\\n\\ninput:\\n\\\"JAIPUR: Four persons died while one was injured in an accident between a car and a private bus in Rajasthan's Dungarpur district, police said on Saturday. The incident occurred late Friday night on NH 48 in Bichhiwada when the car, traveling in the wrong direction, collided with a private bus heading towards Dungarpur. The impact of the collision was so severe that it left the car's front end completely demolished, police said. The four young individuals who died have been identified as Satish Bhai (25), Ankit Ninama (25), Ravi (23), and Kaushik (21). All of them hailed from Shamlaji in Gujarat, according to the police. The bodies of the deceased have been placed in the district hospital's mortuary, and their family members have been notified of the accident. Once their relatives arrive, post-mortem examinations will be conducted, police said. (With inputs from PTI) Explore Your Financial Landscape with Personalized Credit Insights.\\\"\\n\\noutput:{\\\"fatalities\\\": 4,\\\"injured\\\":1,\\\"reason\\\":'wrong direction',\\\"victim_gender\\\":[\\\"Female\\\",\\\"Male\\\"],\\\"vehicles\\\":[\\\"tractor-trolley\\\",\\\"car\\\"],\\\"child_involved\\\":0,\\\"names_ages\\\":[(\\\"Satish Bhai\\\",25),(\\\"Ankit Ninama\\\",25),(\\\"Ravi\\\",23),(\\\"Kaushik\\\",21)]}/\\n\\n\\n\\ninput:\\n\\\"KHARGONE: Three policemen, including two sub-inspectors died, and two critically injured when their car rammed into a parked truck in MP 's Khragone district early Saturday morning. The victims were returning to Sanawad town, 70km from the district headquarters, after completing their duties at the annual fair in Shivdola, another 70km away, said police. At 5.30am near Badud village, just 4km short of destination, their hatchback slammed into the rear of a truck parked on the roadside, Sanawad police station in charge Nirmal Kumar Shrivas said. SIs Vimal Tiwari and Ramesh Chandra Bhaskare and constable Manoj Kumawat died on the spot, he said. Constables Raghuveer Rawat and civic defence personnel Komal Dangode were severely injured. They have been shifted to Indore, 70km away. Tiwari was a resident of Indore, Kumrawat from Simrol, and Bhaskere, who owned the car, was from Burhanpur. Rescuers had hard time extricating victims from the wreckage The 108 ambulance drivers, Yuvraj Dhodle and Ritesh Mandloi, who took the victims to hospital said that the car was mangled in the collision and they had a hard time extricating them from the wreckage. The bodies have been handed over to their families after autopsy. Nimar Range DIG Chandrashekhar Solanki told TOI that he has ordered an investigation and asked for a report. CCTV footage shows the car hitting the rear of a truck parked near a petrol pump, he said, adding that why the accident happened is being investigated. The families of the deceased police personnel are being provided assistance as per the rules, he said. Explore Your Financial Landscape with Personalized Credit Insights\"]\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"model\",\n",
    "    \"parts\": [\"{\\\"fatalities\\\": 3,\\\"injured\\\":2,\\\"reason\\\":'under investigation',\\\"victim_gender\\\":[\\\"Male\\\"],\\\"vehicles\\\":[\\\"car\\\",\\\"truck\\\"],\\\"child_involved\\\":0,\\\"names_ages\\\":[(\\\"Vimal Tiwari\\\",0),(\\\"Ramesh Chandra Bhaskare\\\",0),(\\\"Manoj Kumawat\\\",0),(\\\"Raghuveer Rawat\\\",0),(\\\"Komal Dangode\\\",0)]}\"]\n",
    "  },\n",
    "])\n",
    "\n",
    "convo.send_message(\"HYDERABAD: A woman and her 13-year-old daughter died in Antharam village in Medakâ€™s Munpalle mandal on Tuesday when the car in which they were travelling was hit by a tractor. Two others in the car escaped with injuries. The deceased have been identified as Swaroopa, 36, and her daughter Sri Lekha . The two injured, Mallesham and Lavanya, have been admitted to a hospital. Police said the accident took place in the early hours. The tractor came in the opposite direction and rammed the car, police said. A case was registered under section 304-A (negligence causing death) of IPC. Tractor driver was also injured in the accident. Explore Your Financial Landscape with Personalized Credit Insights.\")\n",
    "print(convo.last.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d37ff-8e73-4b2b-bcc1-d9c5c98dab14",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LANGUAGE MODEL PROMPT ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b713658-1118-4c6d-8546-17d26ea02219",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dump API calls to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acac9315-467d-4e23-81da-90976f424eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆ                                    | 998/9978 [11:31<20:05,  7.45it/s]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue (y/n)?  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                               | 1998/9978 [58:43<17:01,  7.81it/s]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Continue (y/n)?  n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 1998/9978 [1:02:05<4:07:59,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if extraction_progress.json exists\n",
    "if os.path.exists(\"extraction_progress.json\"):\n",
    "    with open(\"extraction_progress.json\", \"r\") as file:\n",
    "        extraction_progress = json.load(file)\n",
    "else:\n",
    "    extraction_progress = {}\n",
    "\n",
    "# Filter out ids that have already been processed\n",
    "processed_ids = list(map(int, extraction_progress.keys()))\n",
    "\n",
    "remaining_ids = df_livedata[~df_livedata['id'].isin(processed_ids)]\n",
    "\n",
    "count = 1\n",
    "\n",
    "for index, row in tqdm(remaining_ids.iterrows(), total=remaining_ids.shape[0]):\n",
    "    try:\n",
    "        convo.send_message(row['content'])\n",
    "        data_string = convo.last.text\n",
    "    except:\n",
    "        data_string = 'error:llm'\n",
    "\n",
    "    extraction_progress[row['id']] = data_string\n",
    "\n",
    "    with open(\"extraction_progress.json\", \"w\") as file:\n",
    "        json.dump(extraction_progress, file)\n",
    "    \n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        user_input = input(\"Continue (y/n)? \")\n",
    "        if user_input.lower() != 'y':\n",
    "            break\n",
    "    time.sleep(1.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb860ed5-5f8d-4d7d-a97b-8423a60db848",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean up json dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10f7c2c0-7f80-45c1-b7b2-8b3011281801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleanup_json(\"extraction_progress.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a9151-66e2-440a-93a6-b65641406986",
   "metadata": {
    "tags": []
   },
   "source": [
    "# JSON to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c3e795d-c983-41b1-b430-479e224da6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast  # Add this import statement\n",
    "\n",
    "# Check if extraction_progress.json exists\n",
    "if os.path.exists(\"extraction_progress.json\"):\n",
    "    with open(\"extraction_progress.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Create DataFrame with keys and entire JSON string values\n",
    "    df_json = pd.DataFrame(list(data.items()), columns=['ID', 'JSON_String'])\n",
    "\n",
    "    # Function to convert JSON string to dictionary\n",
    "    def json_str_to_dict(json_str):\n",
    "        try:\n",
    "            return ast.literal_eval(json_str)\n",
    "        except:\n",
    "            return \"error:incorrect_format\"\n",
    "\n",
    "    # Convert JSON strings to dictionaries\n",
    "    df_json['JSON_Dict'] = df_json['JSON_String'].apply(json_str_to_dict)\n",
    "\n",
    "    # Convert dictionaries to DataFrame\n",
    "    df = pd.json_normalize(df_json['JSON_Dict'])\n",
    "\n",
    "    # Concatenate df_json and df\n",
    "    df_extacted = pd.concat([df_json, df], axis=1)\n",
    "    print('Extraction complete')\n",
    "else:\n",
    "    print(\"extraction_progress.json file does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07ca1ee4-93e2-490f-b1ab-6d3d72c84600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>JSON_String</th>\n",
       "      <th>JSON_Dict</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>injured</th>\n",
       "      <th>reason</th>\n",
       "      <th>victim_gender</th>\n",
       "      <th>vehicles</th>\n",
       "      <th>child_involved</th>\n",
       "      <th>names_ages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107938160</td>\n",
       "      <td>{\"fatalities\": 3,\"injured\":1,\"reason\":'rash dr...</td>\n",
       "      <td>{'fatalities': 3, 'injured': 1, 'reason': 'ras...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rash driving</td>\n",
       "      <td>[Female, Male]</td>\n",
       "      <td>[car]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(Chinta Devi, 51), (Ram Chandra Gupta, 55), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107821301</td>\n",
       "      <td>{\"fatalities\": 3,\"injured\":0,\"reason\":'brakes ...</td>\n",
       "      <td>{'fatalities': 3, 'injured': 0, 'reason': 'bra...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>brakes applied</td>\n",
       "      <td>[Male]</td>\n",
       "      <td>[car, truck]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(Ravinder Kumar, 0), (Subhash Kumar, 0), (Aja...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                        JSON_String  \\\n",
       "0  107938160  {\"fatalities\": 3,\"injured\":1,\"reason\":'rash dr...   \n",
       "1  107821301  {\"fatalities\": 3,\"injured\":0,\"reason\":'brakes ...   \n",
       "\n",
       "                                           JSON_Dict  fatalities  injured  \\\n",
       "0  {'fatalities': 3, 'injured': 1, 'reason': 'ras...         3.0      1.0   \n",
       "1  {'fatalities': 3, 'injured': 0, 'reason': 'bra...         3.0      0.0   \n",
       "\n",
       "           reason   victim_gender      vehicles  child_involved  \\\n",
       "0    rash driving  [Female, Male]         [car]             0.0   \n",
       "1  brakes applied          [Male]  [car, truck]             0.0   \n",
       "\n",
       "                                          names_ages  \n",
       "0  [(Chinta Devi, 51), (Ram Chandra Gupta, 55), (...  \n",
       "1  [(Ravinder Kumar, 0), (Subhash Kumar, 0), (Aja...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extacted.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d30a91ac-9e48-4b27-859b-a08273db9d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extacted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756fbd6-12f0-4277-a8cf-f7088182fd84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# SAVE TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7991126a-ae69-4234-8265-2ac3d6f7c136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_extacted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_extacted\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_extracted_llm_gemini.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_extacted' is not defined"
     ]
    }
   ],
   "source": [
    "df_extacted.to_csv('data_extracted_llm_gemini.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf59336-d8bd-486d-9aa2-854ee517c9dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# backup_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c17e9f9b-76da-4088-9a65-f26e256d553c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  7.06s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if extraction_progress.json exists\n",
    "if os.path.exists(\"extraction_progress.json\"):\n",
    "    with open(\"extraction_progress.json\", \"r\") as file:\n",
    "        extraction_progress = json.load(file)\n",
    "else:\n",
    "    extraction_progress = {}\n",
    "\n",
    "# Convert extraction_progress keys to list for filtering\n",
    "processed_ids = list(extraction_progress.keys())\n",
    "\n",
    "# Filter out ids that have already been processed\n",
    "remaining_ids = df_livedata[~df_livedata['id'].isin(processed_ids)]\n",
    "\n",
    "for index, row in tqdm(remaining_ids.head(10).iterrows(), total=min(10, remaining_ids.shape[0])):\n",
    "    try:\n",
    "        convo.send_message(row['content'])\n",
    "        data_string = convo.last.text\n",
    "    except:\n",
    "        data_string = 'error:llm'\n",
    "\n",
    "    df_livedata.loc[index, 'llm_completion_dict'] = data_string\n",
    "    extraction_progress[row['id']] = data_string\n",
    "\n",
    "    # Save extraction progress to extraction_progress.json after each iteration\n",
    "    with open(\"extraction_progress.json\", \"w\") as file:\n",
    "        json.dump(extraction_progress, file)\n",
    "\n",
    "# Save the updated df_livedata to a JSON file\n",
    "df_livedata[['id', 'llm_completion_dict']].to_json(\"extraction_data.json\", orient=\"records\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
