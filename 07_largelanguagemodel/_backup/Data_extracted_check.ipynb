{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c86b8d98-109c-4ac9-8f52-d78fc4046385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('data_extracted_transformed_openai.csv')\n",
    "\n",
    "df = pd.read_csv('llm_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9f78f02-6efd-4410-ba87-7f6aa9416907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Unique values*******\n",
      "__________ \n",
      "\n",
      "['55,22' '32' '50,19' '30,26,27' '17-year-old, 42-year-old' nan\n",
      " '57,55,27,22,20,25' '38' '53,35,31' '25' '16,13,18' '29,23,25' '42,23,48'\n",
      " '34' '71' '80,54,51' '40,11,7' '26, 32' '50, 42' '1.5' '22,24,20'\n",
      " '42,12,6' '35' '35,29,20,31' '2' '38,36,11,7' '34, 67'\n",
      " '35,9,55, 25, 42,45,14,25,14,9' '25, 43,52' '32,22,20,19'\n",
      " '26,2,9 months, 6 months' '35,38,14,9,4' '28,10,67']\n",
      "__________ \n",
      "\n",
      "['bike, car' 'bike,Dumper(truck),car' 'bike, truck, bus' 'car, truck'\n",
      " 'bike,truck, car, concrete mixing vehicle' 'pickup vehicle, car' 'car'\n",
      " 'car, truck,bus' 'bike,car' 'car,trucks' 'car,truck' 'autorickshaw, bike'\n",
      " 'car,bike' 'truck,trailer,car' 'motorcycle,car,truck' 'truck,car'\n",
      " 'car,motorcycle' 'car,minibus' 'taxi,sedan' 'car,lorry'\n",
      " 'four-wheeler,car' 'truck, car' 'car, JCB' 'two-wheeler,bus,car'\n",
      " 'van,bus' 'two-wheelers, autorickshaw' 'canter truck,car'\n",
      " 'car, container truck' 'cargo truck, motorcycle, car' 'car,two-wheeler'\n",
      " 'car, jeep']\n",
      "__________ \n",
      "\n",
      "[nan 'dozed off' 'speeding' 'Visibility' 'External influences'\n",
      " 'rammed a tree' 'lost balance' 'hit-and-run, driving on the other side'\n",
      " 'over-speeding' 'lost control' 'Driving Under Influence' 'boulder'\n",
      " 'asleep' 'hit by oncoming truck' 'hit-and-run,speeding'\n",
      " 'head-on collision']\n",
      "__________ \n",
      "\n",
      "[ 2.  3. nan  4.  1.  5.]\n",
      "__________ \n",
      "\n",
      "[nan  3.  2.  4.  1.  8.]\n",
      "__________ \n",
      "\n",
      "['Female,Male' 'Male' 'Female' nan 'woman, grandson'\n",
      " 'male,female,male,male,female,female' 'male,female' 'male,male' 'male'\n",
      " 'male,male,male' 'male,male,female,male' 'female,male,male' 'female'\n",
      " 'male,child' 'male,male,male,male' 'woman' 'male,female,female,female'\n",
      " 'female,male,female,male,male,male,female,female,male'\n",
      " 'female,female,female,male' 'male,male,male,male,male,male']\n",
      "__________ \n",
      "\n",
      "[nan 'Night' 'morning' 'evening' 'early hours' 'night,morning' 'night'\n",
      " 'afternoon' 'midnight']\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = ['age','vehicle_type', 'reason', 'fatalities', 'injured', 'gender', 'time']\n",
    "print('*******Unique values*******')\n",
    "for columns in columns_to_check:\n",
    "    print('_'*10,'\\n')\n",
    "    print(df[columns].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b23efff-30c9-4086-aab6-1470476696bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b794c-6832-43b8-baa6-607951a1c747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4fcefc-1161-4082-8a71-409bb462255c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "164ae8db-9d61-4cf8-bbf3-68690136ab10",
   "metadata": {
    "tags": []
   },
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from datetime import datetime\n",
    "from word2number import w2n\n",
    "from tqdm import tqdm# __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11b583a5-dfc9-4411-a013-c3b2e670b1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from datetime import datetime\n",
    "from word2number import w2n\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1fd141-b488-4d99-a433-2c2b6ad8a5cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cc293d2-0aa8-4cff-b59d-b4fd3aa6dee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to handle number of injured and fatalities when there's only a single entry\n",
    "def text_to_single_number(text):\n",
    "    try:\n",
    "        # Parse the text to extract numbers\n",
    "        numbers = [w2n.word_to_num(item.strip()) if '.' not in item else float(item.strip()) \n",
    "                   for item in text.strip('[]').split(',') if item.strip()]\n",
    "        # Return the number if there's exactly one, or np.nan otherwise\n",
    "        return numbers[0] if len(numbers) == 1 else np.nan\n",
    "    except ValueError:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "829caa81-b181-474f-8898-424554f74baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to handle reason of accident\n",
    "reason_mappings = {\n",
    "    'Speed': ['speeding', 'speed', 'racing', 'joy'],\n",
    "    'Driving Under Influence': ['drunk', 'drunken', 'alcohol', 'drink', 'drug'],\n",
    "    'Collision': ['hit-and-run', 'collided', 'collision', 'mowing', 'mow', 'rammed','hit','accident'],\n",
    "    'Visibility': ['fog', 'fogged', 'smog', 'light','rain'],\n",
    "    'Negligence': ['negligence','skid','wrong side','negligent', 'rash', 'reckless', 'dozed','abrupt','control','rear-ended','sleep','crossing','jaywalking'],\n",
    "    'External influences': ['tree','cattle','divider', 'rock', 'stones', 'brick','electric', 'electricity', 'dementia', 'tyre', 'overloaded']\n",
    "}\n",
    "# Function to handle reason of accident with hierarchy\n",
    "def categorize_accident_reason(reason_str):\n",
    "    if pd.isnull(reason_str):\n",
    "        return np.nan\n",
    "\n",
    "    reason_str = reason_str.lower()\n",
    "    categories = set()\n",
    "    \n",
    "    # Extract reason terms from the string, handling lists\n",
    "    reason_list = re.findall(r'[\\w-]+', reason_str.replace('[', '').replace(']', ''))\n",
    "    \n",
    "    # Reason hierarchy dictionary (lower number means higher priority)\n",
    "    reason_hierarchy = {\n",
    "        'Driving Under Influence': 1,\n",
    "        'Speed': 2,\n",
    "        'Negligence': 3,\n",
    "        'Collision': 4,\n",
    "        'Visibility': 5,\n",
    "        'External influences': 6\n",
    "    }\n",
    "    \n",
    "    # Identify categories for each reason term\n",
    "    min_priority = float('inf')\n",
    "    selected_category = np.nan\n",
    "    \n",
    "    for reason in reason_list:\n",
    "        for category, keywords in reason_mappings.items():\n",
    "            if any(keyword in reason for keyword in keywords):\n",
    "                current_priority = reason_hierarchy.get(category, float('inf'))\n",
    "                # Check if the current category has higher priority\n",
    "                if current_priority < min_priority:\n",
    "                    min_priority = current_priority\n",
    "                    selected_category = category\n",
    "    return selected_category\n",
    "\n",
    "\n",
    "# # Reapply the function to the 'REASON' column\n",
    "# predictions['REASON'] = predictions['REASON'].apply(categorize_accident_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48bbf19e-e863-491c-914a-7bafe899aa73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to handle gender\n",
    "male_keywords = {'man', 'men', 'boy', 'boys', 'son', 'sons', 'he', 'his', 'him', 'brother', 'brothers', 'father', 'grandfather', 'grandson', 'husband', 'businessman', 'businessmen', 'policeman', 'policemen', 'cameraman', 'male', 'nephew', 'uncle'}\n",
    "female_keywords = {'woman', 'women', 'girl', 'girls', 'daughter', 'daughters', 'she', 'her', 'sister', 'sisters', 'mother', 'grandmother', 'granddaughter', 'wife', 'businesswoman', 'policewoman', 'female', 'niece', 'aunt', 'lady'}\n",
    "def classify_gender(gender_str):\n",
    "    gender_str = re.sub(r'[\\[\\]\\']', '', gender_str)\n",
    "    \n",
    "    \n",
    "    if pd.isnull(gender_str):\n",
    "        return np.nan\n",
    "\n",
    "    tokens = set(re.split(r'[,\\s\\[\\]]+', gender_str.lower()))\n",
    "    identified_genders = []\n",
    "    if any(token in male_keywords for token in tokens):\n",
    "        identified_genders.append('Male')\n",
    "    if any(token in female_keywords for token in tokens):\n",
    "        identified_genders.append('Female')\n",
    "    return identified_genders[0] if len(identified_genders) == 1 else identified_genders if identified_genders else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e14b594-0f41-4785-ac81-8cc50ca93520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def extract_numbers(input_string):\n",
    "#     numbers = re.findall(r'\\d+', input_string)\n",
    "#     numbers = [int(num) for num in numbers]\n",
    "#     if len(numbers) == 0:\n",
    "#         return np.nan\n",
    "#     else:\n",
    "#         return numbers\n",
    "    \n",
    "    \n",
    "def extract_numbers(input_string):\n",
    "    numbers = re.findall(r'\\d+', input_string)\n",
    "    numbers = [int(num) if int(num) != 0 else 1 for num in numbers]\n",
    "    numbers = [num for num in numbers if num <= 100]\n",
    "    if len(numbers) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return numbers\n",
    "\n",
    "# # Given string\n",
    "# given_string = \"[('Chinta Devi', 51), ('Ram Chandra Gupta', 55), ('Maya Devi', 52), ('Vikas', 30)]\"\n",
    "\n",
    "# # Extract numbers from the given string\n",
    "# extracted_numbers = extract_numbers(given_string)\n",
    "\n",
    "# print(extracted_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62963ae9-1d87-4efa-ab61-faa16b829818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_time(input_data):\n",
    "    # Regular expression pattern to match morning, afternoon, evening, or night\n",
    "    time_pattern = r'(morning|afternoon|evening|night)'\n",
    "    \n",
    "    # If input_data is a list\n",
    "    if isinstance(input_data, list):\n",
    "        # Iterate through the list\n",
    "        for item in input_data:\n",
    "            # If the item is not 'NA', try to find a match\n",
    "            if item != 'NA':\n",
    "                match = re.search(time_pattern, item)\n",
    "                # If a match is found, return it\n",
    "                if match:\n",
    "                    return match.group()\n",
    "    # If input_data is a string\n",
    "    elif isinstance(input_data, str):\n",
    "        # Find all matches in the input string\n",
    "        matches = re.findall(time_pattern, input_data)\n",
    "        # If matches are found, return the first match, else return None\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    # If no match is found, return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e131333-dcd4-4a08-a2bd-f844500135c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_unique_vehicles(input_string):\n",
    "    allowed_words = ['Two-Wheeler', 'Special Vehicle', 'Commercial Vehicle', 'Car']\n",
    "    # Remove brackets and single quotes, split the string into words\n",
    "    words = input_string.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    # Extract unique words\n",
    "    unique_words = list(set(words))\n",
    "    # Filter out words not in the allowed list\n",
    "    filtered_words = [word for word in unique_words if word in allowed_words]\n",
    "    \n",
    "    if len(filtered_words) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f8dd726-bfe5-4752-9b29-d5468b904984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_unique_reasons(input_string):\n",
    "    allowed_words = ['Negligence', 'Collision', 'External influences', 'Speed', 'Driving Under Influence']\n",
    "    # Remove brackets and single quotes, split the string into words\n",
    "    words = input_string.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    # Extract unique words\n",
    "    unique_words = list(set(words))\n",
    "    # Filter out words not in the allowed list\n",
    "    filtered_words = [word for word in unique_words if word in allowed_words]\n",
    "    \n",
    "    if len(filtered_words) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7965da-1faa-4349-821e-f8b5056611bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92680a73-9805-4604-a687-52f9284b12ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['fatalities'] = df['fatalities'].astype(str).apply(text_to_single_number)\n",
    "df['injured'] = df['injured'].astype(str).apply(text_to_single_number)\n",
    "df['gender'] = df['gender'].astype(str).apply(classify_gender)\n",
    "df['age'] = df['age'].astype(str).apply(extract_numbers)\n",
    "df['time'] = df['time'].astype(str).apply(extract_time)\n",
    "df['vehicle_type'] = df['vehicle_type'].astype(str).apply(extract_unique_vehicles)\n",
    "df['reason'] = df['reason'].astype(str).apply(categorize_accident_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa3f1258-9808-4627-bc66-b4f2e905bc8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('llm_test_data_t.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "764faa19-8c1b-4f99-b83e-6a447a0f415e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('llm_test_data_t.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ef0834a-5a64-433d-93b8-ddc1178f447c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Unique values*******\n",
      "__________ \n",
      "\n",
      "['[55, 22]' '[32]' '[50, 19]' '[30, 26, 27]' '[17, 42]' nan\n",
      " '[57, 55, 27, 22, 20, 25]' '[38]' '[53, 35, 31]' '[25]' '[16, 13, 18]'\n",
      " '[29, 23, 25]' '[42, 23, 48]' '[34]' '[71]' '[80, 54, 51]' '[40, 11, 7]'\n",
      " '[26, 32]' '[50, 42]' '[1, 5]' '[22, 24, 20]' '[42, 12, 6]' '[35]'\n",
      " '[35, 29, 20, 31]' '[2]' '[38, 36, 11, 7]' '[34, 67]'\n",
      " '[35, 9, 55, 25, 42, 45, 14, 25, 14, 9]' '[25, 43, 52]'\n",
      " '[32, 22, 20, 19]' '[26, 2, 9, 6]' '[35, 38, 14, 9, 4]' '[28, 10, 67]']\n",
      "__________ \n",
      "\n",
      "[nan]\n",
      "__________ \n",
      "\n",
      "[nan 'Negligence' 'Speed' 'Collision']\n",
      "__________ \n",
      "\n",
      "[ 2.  3. nan  4.  1.  5.]\n",
      "__________ \n",
      "\n",
      "[nan  3.  2.  4.  1.  8.]\n",
      "__________ \n",
      "\n",
      "[\"['Male', 'Female']\" 'Male' 'Female' nan]\n",
      "__________ \n",
      "\n",
      "[nan 'morning' 'evening' 'night' 'afternoon']\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = ['age','vehicle_type', 'reason', 'fatalities', 'injured', 'gender', 'time']\n",
    "print('*******Unique values*******')\n",
    "for columns in columns_to_check:\n",
    "    print('_'*10,'\\n')\n",
    "    print(df[columns].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b120e8-9073-468f-bec9-2e68c44c82bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
