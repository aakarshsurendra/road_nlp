{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa88466-b5d3-4a1e-89b4-623c8fdde9eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4116e57-e94f-4f18-b2f0-1fc62aacedaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aakarshsurendra/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/aakarshsurendra/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import json\n",
    "import spacy_transformers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3864d94-16d6-41f0-a2d7-6cab98767d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de52d7d-b7d6-467d-ade4-4c4f31bd531c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_data_to_pickle(data, filename):\n",
    "    \"\"\"\n",
    "    Save data to a pickle file.\n",
    "    \n",
    "    Parameters:\n",
    "        data: The data to be saved.\n",
    "        filename (str): The filename of the pickle file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {filename} successfully.\")\n",
    "\n",
    "def load_data_from_pickle(filename):\n",
    "    \"\"\"\n",
    "    Load data from a pickle file.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): The filename of the pickle file.\n",
    "        \n",
    "    Returns:\n",
    "        The loaded data.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Data loaded from {filename} successfully.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fd731-14f6-49d0-920f-876d92ddc239",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11b95186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading the filtered news dataset from a CSV file into a DataFrame, setting the index to None\n",
    "dataframe = pd.read_csv('input/entity_data.csv', index_col=None)\n",
    "\n",
    "# Selecting specific columns from the filtered dataset\n",
    "dataframe = dataframe[['id', 'place','Link', 'content', 'News_date', 'First_Line','latitude','longitude','state','week_avg_weather','precipitation_3days']]\n",
    "\n",
    "dataframe = dataframe.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8c54c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Annotated_data to spaCy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d45beb07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Specify the file path\n",
    "file_path = \"input/annotations.json\"\n",
    "\n",
    "# Open the file and load its contents as JSON\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "annotations = data.get(\"annotations\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd4f9106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe['annotations'] = annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35527d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe[dataframe['annotations'] != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e758d511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "place                   0\n",
       "Link                    0\n",
       "content                 0\n",
       "News_date               0\n",
       "First_Line              0\n",
       "latitude               20\n",
       "longitude              20\n",
       "state                  20\n",
       "week_avg_weather       20\n",
       "precipitation_3days    20\n",
       "annotations            39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02641530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   1000 non-null   int64  \n",
      " 1   place                1000 non-null   object \n",
      " 2   Link                 1000 non-null   object \n",
      " 3   content              1000 non-null   object \n",
      " 4   News_date            1000 non-null   object \n",
      " 5   First_Line           1000 non-null   object \n",
      " 6   latitude             980 non-null    float64\n",
      " 7   longitude            980 non-null    float64\n",
      " 8   state                980 non-null    object \n",
      " 9   week_avg_weather     980 non-null    float64\n",
      " 10  precipitation_3days  980 non-null    float64\n",
      " 11  annotations          961 non-null    object \n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 101.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d34d96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Converting annotations into spaCy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21dbf94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = dataframe['annotations'][:800]\n",
    "test_data = dataframe['annotations'][800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91fba704-743b-4f60-bd64-7f05d77b6149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 1\n",
    "train_data = pd.concat([train_data] * N, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db124d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entity_names = [\"AGE\", \"VEHICLE TYPE\", \"REASON\", \"FATALITIES\", \"INJURED\", \"GENDER\", \"TIME\"]\n",
    "\n",
    "train_data = train_data.tolist()\n",
    "test_data = test_data.tolist()\n",
    "\n",
    "if train_data is not None:  # Check if 'train_data' is not None\n",
    "    train_data = [tuple(i) for i in train_data if i is not None]  # Convert 'train_data' to list of tuples, excluding any None values\n",
    "    # Further processing if needed\n",
    "else:\n",
    "    print(\"Annotations data is not available or is None \")\n",
    "    \n",
    "if test_data is not None:  # Check if 'test_data' is not None\n",
    "    test_data = [tuple(i) for i in test_data if i is not None]  # Convert 'test_data' to list of tuples, excluding any None values\n",
    "    # Further processing if needed\n",
    "else:\n",
    "    print(\"Annotations data is not available or is None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b99aa04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through each item in the train_data list\n",
    "for i in train_data:\n",
    "    # Check if the 'entities' list in the current item is empty\n",
    "    if i[1]['entities'] == []:\n",
    "        # If it's empty, populate it with default tuples (0, 0, name) \n",
    "        # where 'name' is iterated over all elements in 'entity_names'\n",
    "        i[1]['entities'] = [(0, 0, name) for name in entity_names]\n",
    "    else:\n",
    "        # If 'entities' list is not empty, convert each element to a tuple\n",
    "        i[1]['entities'] = [tuple(entity) for entity in i[1]['entities']]\n",
    "\n",
    "# Loop through each item in the test_data list\n",
    "for i in test_data:\n",
    "    # Check if the 'entities' list in the current item is empty\n",
    "    if i[1]['entities'] == []:\n",
    "        # If it's empty, populate it with default tuples (0, 0, name) \n",
    "        # where 'name' is iterated over all elements in 'entity_names'\n",
    "        i[1]['entities'] = [(0, 0, name) for name in entity_names]\n",
    "    else:\n",
    "        # If 'entities' list is not empty, convert each element to a tuple\n",
    "        i[1]['entities'] = [tuple(entity) for entity in i[1]['entities']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4e3cc4a-6650-41ba-8231-5ed69b50dbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_data: 775\n",
      "Length of test_data: 186\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of train_data: {len(train_data)}\\nLength of test_data: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f3ff43-ed59-4d55-8fda-363663c40997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e6f23-cfea-43cd-a6c4-592a156e2d51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train Data to Doc bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c58a1449-70f1-45ad-82d6-52562a97c68b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.blank(\"en\") # load a new spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2de89bad-b8b6-4f5e-8e99-dd31520ddb56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9d0766b-118e-4915-ad87-467ef57b2d83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_data: 100%|████████████████| 775/775 [00:00<00:00, 6732.79it/s]\n"
     ]
    }
   ],
   "source": [
    "db = DocBin()\n",
    "\n",
    "for data in tqdm(train_data, desc=\"Processing train_data\"):\n",
    "    if data is None:\n",
    "        print(\"Encountered a null value in train_data. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    text, annot = data\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "\n",
    "    if annot is not None and \"entities\" in annot:  # Check if annot is not None and contains \"entities\" key\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                # print(\"Skipping entity\")\n",
    "                pass\n",
    "            else:\n",
    "                ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30ed264b-05a4-4672-89cc-2f7c399097f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db.to_disk(\"train.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d794a-b4aa-475a-ad93-430f795f04ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train Data to Doc bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e834e6bc-5c2b-4d98-910f-13903905cb08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_test = DocBin()\n",
    "\n",
    "for data in test_data:\n",
    "    if data is None:\n",
    "        print(\"Encountered a null value in train_data. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    text, annot = data\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "\n",
    "    if annot is not None and \"entities\" in annot:  # Check if annot is not None and contains \"entities\" key\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                # print(\"Skipping entity\")\n",
    "                pass\n",
    "            else:\n",
    "                ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db_test.add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95ee9976-a903-42c1-bd9a-1cfbff32ada7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_test.to_disk(\"test.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e4994-fe89-4fdb-a585-88436bb0ffc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a02e261-c150-4ba5-a522-e3b923aa7c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to train_data.pickle successfully.\n",
      "Data saved to test_data.pickle successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save train_data to a pickle file\n",
    "save_data_to_pickle(train_data, \"train_data.pickle\")\n",
    "save_data_to_pickle(test_data, \"test_data.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
